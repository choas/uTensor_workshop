// Auto generated by utensor-cli

#include "uTensor/core/context.hpp"
#include "xor_relu_weight.hpp"
#include "uTensor/core/tensor.hpp"
#include "uTensor/ops/NnOps.hpp"
#include "xor_relu.hpp"
#include "uTensor/ops/MatrixOps.hpp"
#include "uTensor/ops/MathOps.hpp"
#include "uTensor/ops/ArrayOps.hpp"


void get_xor_relu_ctx(Context& ctx, Tensor* input_0) {

{ // add tensor for placeholders
    ctx.add(input_0, "Placeholder:0", 2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_MatMul_eightbit_Placeholder__port__0_reshape_dims_0), 
            "MatMul_eightbit/Placeholder__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "MatMul_eightbit/Placeholder__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "Placeholder:0", "MatMul_eightbit/Placeholder__port__0/reshape_dims:0" },
             { "MatMul_eightbit/Placeholder__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_MatMul_eightbit_Placeholder__port__0_reduction_dims_0), 
            "MatMul_eightbit/Placeholder__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "MatMul_eightbit/Placeholder__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "MatMul_eightbit/Placeholder__port__0/reshape:0", "MatMul_eightbit/Placeholder__port__0/reduction_dims:0" },
             { "MatMul_eightbit/Placeholder__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "MatMul_eightbit/Placeholder__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "MatMul_eightbit/Placeholder__port__0/reshape:0", "MatMul_eightbit/Placeholder__port__0/reduction_dims:0" },
             { "MatMul_eightbit/Placeholder__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "MatMul_eightbit/Placeholder__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_eightbit/Placeholder__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_eightbit/Placeholder__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "Placeholder:0",  "MatMul_eightbit/Placeholder__port__0/min:0", "MatMul_eightbit/Placeholder__port__0/max:0" },
             {  "MatMul_eightbit/Placeholder__port__0/quantize:0",  "MatMul_eightbit/Placeholder__port__0/quantize:1", "MatMul_eightbit/Placeholder__port__0/quantize:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({2,10}, inline_Variable_0), 
            "Variable:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_MatMul_eightbit_Variable__port__0_reshape_dims_0), 
            "MatMul_eightbit/Variable__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "MatMul_eightbit/Variable__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "Variable:0", "MatMul_eightbit/Variable__port__0/reshape_dims:0" },
             { "MatMul_eightbit/Variable__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_MatMul_eightbit_Variable__port__0_reduction_dims_0), 
            "MatMul_eightbit/Variable__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "MatMul_eightbit/Variable__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "MatMul_eightbit/Variable__port__0/reshape:0", "MatMul_eightbit/Variable__port__0/reduction_dims:0" },
             { "MatMul_eightbit/Variable__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "MatMul_eightbit/Variable__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "MatMul_eightbit/Variable__port__0/reshape:0", "MatMul_eightbit/Variable__port__0/reduction_dims:0" },
             { "MatMul_eightbit/Variable__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "MatMul_eightbit/Variable__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_eightbit/Variable__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_eightbit/Variable__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "Variable:0",  "MatMul_eightbit/Variable__port__0/min:0", "MatMul_eightbit/Variable__port__0/max:0" },
             {  "MatMul_eightbit/Variable__port__0/quantize:0",  "MatMul_eightbit/Variable__port__0/quantize:1", "MatMul_eightbit/Variable__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "MatMul/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "MatMul/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "MatMul/eightbit:2", 2);
    ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
             { "MatMul_eightbit/Placeholder__port__0/quantize:0", "MatMul_eightbit/Placeholder__port__0/quantize:1", "MatMul_eightbit/Placeholder__port__0/quantize:2", "MatMul_eightbit/Variable__port__0/quantize:0", "MatMul_eightbit/Variable__port__0/quantize:1",  "MatMul_eightbit/Variable__port__0/quantize:2" },
             { "MatMul/eightbit:0", "MatMul/eightbit:1",  "MatMul/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "MatMul/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "MatMul/eightbit:0", "MatMul/eightbit:1", "MatMul/eightbit:2" },
             { "MatMul/eightbit/requant_range:0", "MatMul/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "MatMul/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "MatMul/eightbit:0", "MatMul/eightbit:1", "MatMul/eightbit:2", "MatMul/eightbit/requant_range:0", "MatMul/eightbit/requant_range:1" },
             { "MatMul/eightbit/requantize:0", "MatMul/eightbit/requantize:1", "MatMul/eightbit/requantize:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({10}, inline_Variable_1_0), 
            "Variable_1:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_add_eightbit_Variable_1__port__0_reshape_dims_0), 
            "add_eightbit/Variable_1__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "add_eightbit/Variable_1__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "Variable_1:0", "add_eightbit/Variable_1__port__0/reshape_dims:0" },
             { "add_eightbit/Variable_1__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_add_eightbit_Variable_1__port__0_reduction_dims_0), 
            "add_eightbit/Variable_1__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "add_eightbit/Variable_1__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "add_eightbit/Variable_1__port__0/reshape:0", "add_eightbit/Variable_1__port__0/reduction_dims:0" },
             { "add_eightbit/Variable_1__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "add_eightbit/Variable_1__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "add_eightbit/Variable_1__port__0/reshape:0", "add_eightbit/Variable_1__port__0/reduction_dims:0" },
             { "add_eightbit/Variable_1__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "add_eightbit/Variable_1__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "add_eightbit/Variable_1__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "add_eightbit/Variable_1__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "Variable_1:0",  "add_eightbit/Variable_1__port__0/min:0", "add_eightbit/Variable_1__port__0/max:0" },
             {  "add_eightbit/Variable_1__port__0/quantize:0",  "add_eightbit/Variable_1__port__0/quantize:1", "add_eightbit/Variable_1__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "add/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "add/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "add/eightbit:2", 2);
    ctx.push(new QuantizedAddOp<uint8_t, uint8_t, int>(), 
             { "MatMul/eightbit/requantize:0", "MatMul/eightbit/requantize:1", "MatMul/eightbit/requantize:2", "add_eightbit/Variable_1__port__0/quantize:0", "add_eightbit/Variable_1__port__0/quantize:1",  "add_eightbit/Variable_1__port__0/quantize:2" },
             { "add/eightbit:0", "add/eightbit:1",  "add/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "add/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "add/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "add/eightbit:0", "add/eightbit:1", "add/eightbit:2" },
             { "add/eightbit/requant_range:0", "add/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "add/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "add/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "add/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "add/eightbit:0", "add/eightbit:1", "add/eightbit:2", "add/eightbit/requant_range:0", "add/eightbit/requant_range:1" },
             { "add/eightbit/requantize:0", "add/eightbit/requantize:1", "add/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "Relu/eightbit:0", 1);
    ctx.add(new RamTensor<float>({1}), "Relu/eightbit:1", 1);
    ctx.add(new RamTensor<float>({1}), "Relu/eightbit:2", 1);
    ctx.push(new ReluOp<uint8_t, float, uint8_t>(), 
             { "add/eightbit/requantize:0", "add/eightbit/requantize:1", "add/eightbit/requantize:2" },
             { "Relu/eightbit:0", "Relu/eightbit:1", "Relu/eightbit:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({10,2}, inline_Variable_2_0), 
            "Variable_2:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_MatMul_1_eightbit_Variable_2__port__0_reshape_dims_0), 
            "MatMul_1_eightbit/Variable_2__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "MatMul_1_eightbit/Variable_2__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "Variable_2:0", "MatMul_1_eightbit/Variable_2__port__0/reshape_dims:0" },
             { "MatMul_1_eightbit/Variable_2__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_MatMul_1_eightbit_Variable_2__port__0_reduction_dims_0), 
            "MatMul_1_eightbit/Variable_2__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "MatMul_1_eightbit/Variable_2__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "MatMul_1_eightbit/Variable_2__port__0/reshape:0", "MatMul_1_eightbit/Variable_2__port__0/reduction_dims:0" },
             { "MatMul_1_eightbit/Variable_2__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "MatMul_1_eightbit/Variable_2__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "MatMul_1_eightbit/Variable_2__port__0/reshape:0", "MatMul_1_eightbit/Variable_2__port__0/reduction_dims:0" },
             { "MatMul_1_eightbit/Variable_2__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "MatMul_1_eightbit/Variable_2__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_1_eightbit/Variable_2__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_1_eightbit/Variable_2__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "Variable_2:0",  "MatMul_1_eightbit/Variable_2__port__0/min:0", "MatMul_1_eightbit/Variable_2__port__0/max:0" },
             {  "MatMul_1_eightbit/Variable_2__port__0/quantize:0",  "MatMul_1_eightbit/Variable_2__port__0/quantize:1", "MatMul_1_eightbit/Variable_2__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "MatMul_1/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "MatMul_1/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "MatMul_1/eightbit:2", 2);
    ctx.push(new QntMatMulOp<uint8_t, uint8_t, int>(), 
             { "Relu/eightbit:0", "Relu/eightbit:1", "Relu/eightbit:2", "MatMul_1_eightbit/Variable_2__port__0/quantize:0", "MatMul_1_eightbit/Variable_2__port__0/quantize:1",  "MatMul_1_eightbit/Variable_2__port__0/quantize:2" },
             { "MatMul_1/eightbit:0", "MatMul_1/eightbit:1",  "MatMul_1/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "MatMul_1/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_1/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "MatMul_1/eightbit:0", "MatMul_1/eightbit:1", "MatMul_1/eightbit:2" },
             { "MatMul_1/eightbit/requant_range:0", "MatMul_1/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "MatMul_1/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_1/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "MatMul_1/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "MatMul_1/eightbit:0", "MatMul_1/eightbit:1", "MatMul_1/eightbit:2", "MatMul_1/eightbit/requant_range:0", "MatMul_1/eightbit/requant_range:1" },
             { "MatMul_1/eightbit/requantize:0", "MatMul_1/eightbit/requantize:1", "MatMul_1/eightbit/requantize:2" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<float>({2}, inline_Variable_3_0), 
            "Variable_3:0", 
            2);
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_add_1_eightbit_Variable_3__port__0_reshape_dims_0), 
            "add_1_eightbit/Variable_3__port__0/reshape_dims:0", 
            1);
}
{
    ctx.add(new RamTensor<float>(), "add_1_eightbit/Variable_3__port__0/reshape:0", 2);
    ctx.push(new ReshapeOp(), 
             { "Variable_3:0", "add_1_eightbit/Variable_3__port__0/reshape_dims:0" },
             { "add_1_eightbit/Variable_3__port__0/reshape:0" });
    ctx.eval();
}
{    
    ctx.add(new BinaryTensor<int>({1}, inline_add_1_eightbit_Variable_3__port__0_reduction_dims_0), 
            "add_1_eightbit/Variable_3__port__0/reduction_dims:0", 
            2);
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "add_1_eightbit/Variable_3__port__0/min:0", 1);
    ctx.push(new MinOp(), 
             { "add_1_eightbit/Variable_3__port__0/reshape:0", "add_1_eightbit/Variable_3__port__0/reduction_dims:0" },
             { "add_1_eightbit/Variable_3__port__0/min:0" });
    ctx.eval();
}
{   
    RamTensor<float>* out_tensor;
    out_tensor = new RamTensor<float>({ 1 });
    ctx.add(out_tensor, "add_1_eightbit/Variable_3__port__0/max:0", 1);
    ctx.push(new MaxOp(), 
             { "add_1_eightbit/Variable_3__port__0/reshape:0", "add_1_eightbit/Variable_3__port__0/reduction_dims:0" },
             { "add_1_eightbit/Variable_3__port__0/max:0" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<uint8_t>(), "add_1_eightbit/Variable_3__port__0/quantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "add_1_eightbit/Variable_3__port__0/quantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "add_1_eightbit/Variable_3__port__0/quantize:2", 1);
    ctx.push(new QuantizeV2Op(),
             {  "Variable_3:0",  "add_1_eightbit/Variable_3__port__0/min:0", "add_1_eightbit/Variable_3__port__0/max:0" },
             {  "add_1_eightbit/Variable_3__port__0/quantize:0",  "add_1_eightbit/Variable_3__port__0/quantize:1", "add_1_eightbit/Variable_3__port__0/quantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<int>(), "add_1/eightbit:0", 2);
    ctx.add(new RamTensor<float>({1}), "add_1/eightbit:1", 2);
    ctx.add(new RamTensor<float>({1}), "add_1/eightbit:2", 2);
    ctx.push(new QuantizedAddOp<uint8_t, uint8_t, int>(), 
             { "MatMul_1/eightbit/requantize:0", "MatMul_1/eightbit/requantize:1", "MatMul_1/eightbit/requantize:2", "add_1_eightbit/Variable_3__port__0/quantize:0", "add_1_eightbit/Variable_3__port__0/quantize:1",  "add_1_eightbit/Variable_3__port__0/quantize:2" },
             { "add_1/eightbit:0", "add_1/eightbit:1",  "add_1/eightbit:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>({1}), "add_1/eightbit/requant_range:0", 1);
    ctx.add(new RamTensor<float>({1}), "add_1/eightbit/requant_range:1", 1);
    ctx.push(new Requantization_RangeOp(),
             { "add_1/eightbit:0", "add_1/eightbit:1", "add_1/eightbit:2" },
             { "add_1/eightbit/requant_range:0", "add_1/eightbit/requant_range:1" });
    ctx.eval();
}
{   
    ctx.add(new RamTensor<uint8_t>(), "add_1/eightbit/requantize:0", 1);
    ctx.add(new RamTensor<float>({1}), "add_1/eightbit/requantize:1", 1);
    ctx.add(new RamTensor<float>({1}), "add_1/eightbit/requantize:2", 1);
    ctx.push(new RequantizeOp(),
             { "add_1/eightbit:0", "add_1/eightbit:1", "add_1/eightbit:2", "add_1/eightbit/requant_range:0", "add_1/eightbit/requant_range:1" },
             { "add_1/eightbit/requantize:0", "add_1/eightbit/requantize:1", "add_1/eightbit/requantize:2" });
    ctx.eval();
}
{
    ctx.add(new RamTensor<float>(), "add_1:0");
    ctx.push(new DequantizeOp(), 
             { "add_1/eightbit/requantize:0", "add_1/eightbit/requantize:1", "add_1/eightbit/requantize:2" },
             { "add_1:0" });
}
}