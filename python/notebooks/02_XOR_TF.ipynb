{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Weight1' has type str, but expected one of: int, long, bool\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Weight1' has type str, but expected one of: int, long, bool\n",
      "('Epoch ', 0)\n",
      "('Hypothesis ', array([[0.51924896],\n",
      "       [0.5189204 ],\n",
      "       [0.5194725 ],\n",
      "       [0.5191421 ]], dtype=float32))\n",
      "('cost ', 0.69388384)\n",
      "('Epoch ', 10000)\n",
      "('Hypothesis ', array([[0.49994314],\n",
      "       [0.4996525 ],\n",
      "       [0.5003332 ],\n",
      "       [0.5000391 ]], dtype=float32))\n",
      "('cost ', 0.6931456)\n",
      "('Epoch ', 20000)\n",
      "('Hypothesis ', array([[0.4999472 ],\n",
      "       [0.49963441],\n",
      "       [0.5003506 ],\n",
      "       [0.5000343 ]], dtype=float32))\n",
      "('cost ', 0.6931455)\n",
      "('Epoch ', 30000)\n",
      "('Hypothesis ', array([[0.49995124],\n",
      "       [0.49961555],\n",
      "       [0.5003689 ],\n",
      "       [0.5000293 ]], dtype=float32))\n",
      "('cost ', 0.6931454)\n",
      "('Epoch ', 40000)\n",
      "('Hypothesis ', array([[0.49995542],\n",
      "       [0.49959573],\n",
      "       [0.5003881 ],\n",
      "       [0.50002426]], dtype=float32))\n",
      "('cost ', 0.6931453)\n",
      "('Weight1 ', array([[-0.09227301, -0.00650619],\n",
      "       [ 0.14777413, -0.18500277]], dtype=float32))\n",
      "('Bias1 ', array([0.10763127, 0.09981479], dtype=float32))\n",
      "('Weight2 ', array([[-0.07595849],\n",
      "       [-0.0268789 ]], dtype=float32))\n",
      "('Bias2 ', array([0.05397067], dtype=float32))\n",
      "('Elapsed time ', 21.970604)\n"
     ]
    }
   ],
   "source": [
    "#taken from https://aimatters.wordpress.com/2016/01/16/solving-xor-with-a-neural-network-in-tensorflow/\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "XOR_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_Y = [[0],[1],[1],[0]]\n",
    "\n",
    "def weight_variable(shape, name):\n",
    "  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial, name)\n",
    "\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial, name)\n",
    "\n",
    "\n",
    "x_ = tf.placeholder(tf.float32, shape=[4,2], name = 'x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=[4,1], name = 'y-input')\n",
    "\n",
    "# with tf.variable_scope('Layers'):\n",
    "Weight1 = weight_variable([2,2], name=\"Weight1\")\n",
    "Weight2 = weight_variable([2,1], name=\"Weight2\")\n",
    "\n",
    "Bias1 = bias_variable([2], name=\"Bias1\")\n",
    "Bias2 = bias_variable([1], name=\"Bias2\")\n",
    "\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "\tA2 = tf.sigmoid(tf.matmul(x_, Weight1) + Bias1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer3\") as scope:\n",
    "\tHypothesis = tf.sigmoid(tf.matmul(A2, Weight2) + Bias2)\n",
    "\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "\tcost = tf.reduce_mean(( (y_ * tf.log(Hypothesis)) + \n",
    "\t\t((1 - y_) * tf.log(1.0 - Hypothesis)) ) * -1)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "\ttrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "    \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./logs/xor_logs/2nodes\", sess.graph)\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "t_start = time.clock()\n",
    "for i in range(50000):\n",
    "#for i in range(100001):\n",
    "\tsess.run(train_step, feed_dict={x_: XOR_X, y_: XOR_Y})\n",
    "\tif i % 10000 == 0:\n",
    "\t\tprint('Epoch ', i)\n",
    "\t\tprint('Hypothesis ', sess.run(Hypothesis, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "\t\tprint('cost ', sess.run(cost, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "        \n",
    "print('Weight1 ', sess.run(Weight1))\n",
    "print('Bias1 ', sess.run(Bias1))\n",
    "print('Weight2 ', sess.run(Weight2))\n",
    "print('Bias2 ', sess.run(Bias2))\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "#saver.save(sess, \"./xor.pb\")\n",
    "\n",
    "t_end = time.clock()\n",
    "print('Elapsed time ', t_end - t_start)\n",
    "\n",
    "# for op in tf.get_default_graph().get_operations():\n",
    "#     print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch ', 0)\n",
      "('Hypothesis ', array([[0.5930999 ],\n",
      "       [0.5729397 ],\n",
      "       [0.61108035],\n",
      "       [0.59025407]], dtype=float32))\n",
      "('cost ', 0.7102268)\n",
      "('Epoch ', 10000)\n",
      "('Hypothesis ', array([[0.5035934 ],\n",
      "       [0.4826417 ],\n",
      "       [0.51913285],\n",
      "       [0.49556032]], dtype=float32))\n",
      "('cost ', 0.6921857)\n",
      "('Epoch ', 20000)\n",
      "('Hypothesis ', array([[0.505562  ],\n",
      "       [0.46940672],\n",
      "       [0.5379392 ],\n",
      "       [0.49013022]], dtype=float32))\n",
      "('cost ', 0.68855715)\n",
      "('Epoch ', 30000)\n",
      "('Hypothesis ', array([[0.48958266],\n",
      "       [0.42055997],\n",
      "       [0.6364423 ],\n",
      "       [0.46262786]], dtype=float32))\n",
      "('cost ', 0.6529052)\n",
      "('Epoch ', 40000)\n",
      "('Hypothesis ', array([[0.41351685],\n",
      "       [0.35970157],\n",
      "       [0.8433527 ],\n",
      "       [0.39646748]], dtype=float32))\n",
      "('cost ', 0.55785435)\n",
      "('Epoch ', 50000)\n",
      "('Hypothesis ', array([[0.35672814],\n",
      "       [0.41164786],\n",
      "       [0.9114599 ],\n",
      "       [0.35968634]], dtype=float32))\n",
      "('cost ', 0.4668199)\n",
      "('Epoch ', 60000)\n",
      "('Hypothesis ', array([[0.16094044],\n",
      "       [0.8230712 ],\n",
      "       [0.9269265 ],\n",
      "       [0.13216352]], dtype=float32))\n",
      "('cost ', 0.14695477)\n",
      "('Epoch ', 70000)\n",
      "('Hypothesis ', array([[0.0736336 ],\n",
      "       [0.9315652 ],\n",
      "       [0.95488364],\n",
      "       [0.06184123]], dtype=float32))\n",
      "('cost ', 0.06434411)\n",
      "('Epoch ', 80000)\n",
      "('Hypothesis ', array([[0.04611251],\n",
      "       [0.9599494 ],\n",
      "       [0.9689283 ],\n",
      "       [0.03929517]], dtype=float32))\n",
      "('cost ', 0.03993427)\n",
      "('Epoch ', 90000)\n",
      "('Hypothesis ', array([[0.03325241],\n",
      "       [0.9721015 ],\n",
      "       [0.97663   ],\n",
      "       [0.02856223]], dtype=float32))\n",
      "('cost ', 0.028684605)\n",
      "('Epoch ', 100000)\n",
      "('Hypothesis ', array([[0.02589168],\n",
      "       [0.9787202 ],\n",
      "       [0.98138416],\n",
      "       [0.02234969]], dtype=float32))\n",
      "('cost ', 0.022284199)\n",
      "('Weight1 ', array([[-5.597241 ,  6.343999 ],\n",
      "       [ 5.2674527, -6.452686 ]], dtype=float32))\n",
      "('Bias1 ', array([-2.8918147, -3.5797877], dtype=float32))\n",
      "('Weight2 ', array([[8.922872],\n",
      "       [8.822058]], dtype=float32))\n",
      "('Bias2 ', array([-4.335885], dtype=float32))\n",
      "('Elapsed time ', 46.733838)\n"
     ]
    }
   ],
   "source": [
    "# see from https://aimatters.wordpress.com/2016/01/16/solving-xor-with-a-neural-network-in-tensorflow/\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "x_ = tf.placeholder(tf.float32, shape=[4,2], name = 'x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=[4,1], name = 'y-input')\n",
    "\n",
    "Weight1 = tf.Variable(tf.random_uniform([2,2], -1, 1, seed=80636), name = \"Weight1\")\n",
    "Weight2 = tf.Variable(tf.random_uniform([2,1], -1, 1, seed=80636), name = \"Weight2\")\n",
    "\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name = \"Bias1\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name = \"Bias2\")\n",
    "\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "\tA2 = tf.sigmoid(tf.matmul(x_, Weight1) + Bias1)\n",
    "\n",
    "with tf.name_scope(\"layer3\") as scope:\n",
    "\tHypothesis = tf.sigmoid(tf.matmul(A2, Weight2) + Bias2)\n",
    "\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "\tcost = tf.reduce_mean(( (y_ * tf.log(Hypothesis)) + \n",
    "\t\t((1 - y_) * tf.log(1.0 - Hypothesis)) ) * -1)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "\ttrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "XOR_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_Y = [[0],[1],[1],[0]]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./logs/xor_logs/xor_tf\", sess.graph)\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "t_start = time.clock()\n",
    "for i in range(100001):\n",
    "\tsess.run(train_step, feed_dict={x_: XOR_X, y_: XOR_Y})\n",
    "\tif i % 10000 == 0:\n",
    "\t\tprint('Epoch ', i)\n",
    "\t\tprint('Hypothesis ', sess.run(Hypothesis, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "\t\tprint('cost ', sess.run(cost, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "\n",
    "print('Weight1 ', sess.run(Weight1))\n",
    "print('Bias1 ', sess.run(Bias1))\n",
    "print('Weight2 ', sess.run(Weight2))\n",
    "print('Bias2 ', sess.run(Bias2))\n",
    "\n",
    "        \n",
    "t_end = time.clock()\n",
    "print('Elapsed time ', t_end - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02589168]\n",
      " [0.9787202 ]\n",
      " [0.98138416]\n",
      " [0.02234969]]\n"
     ]
    }
   ],
   "source": [
    "print sess.run(Hypothesis, feed_dict={x_: XOR_X, y_: XOR_Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Bias1', u'Bias2', u'Weight2', u'Weight1']\n",
      "[u'layer3/Sigmoid']\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "INFO:tensorflow:Converted 4 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/xor2n.pb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeze_var_names = list(set(v.op.name for v in tf.global_variables()))\n",
    "print freeze_var_names\n",
    "output_names = [Hypothesis.op.name]\n",
    "print output_names\n",
    "\n",
    "from tensorflow.python.framework.graph_util import remove_training_nodes\n",
    "\n",
    "sub_graph_def = remove_training_nodes(sess.graph_def)\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "frozen_graph = graph_util.convert_variables_to_constants(sess, \n",
    "                                                         sub_graph_def, \n",
    "                                                         output_names, \n",
    "                                                         freeze_var_names)\n",
    "\n",
    "tf.train.write_graph(frozen_graph, \"models\", \"xor2n.pb\", as_text=False)\n",
    "#print \"xor.pb written\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utensor-cli convert models/xor2n.pb --output-nodes=layer3_3/Sigmoid\n",
    "# unsupported op type in uTensor: Sigmoid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
